{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tuner import Hyperband\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPooling2D, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CIFAR-10 dataset\n",
    "cifar10 = tf.keras.datasets.cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Normalize the pixel values\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# Split the training set for validation during hyperparameter tuning\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tunable_model(hp):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(1024, activation='relu'),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    optimizer_name = hp.Choice(\"optimizer\", [\"adam\", \"sgd\", \"rmsprop\"])\n",
    "    lr = hp.Float(\"lr\", min_value=1e-5, max_value=1e-1, sampling=\"log\")\n",
    "    \n",
    "    # Choose the optimizer\n",
    "    if optimizer_name == \"adam\":\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    elif optimizer_name == \"sgd\":\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=lr, momentum=0.9)\n",
    "    elif optimizer_name == \"rmsprop\":\n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr)\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = Hyperband(\n",
    "    build_tunable_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=10,\n",
    "    directory=\"hyperparameter_tuning\",\n",
    "    project_name=\"learning_rate_tuning\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 01m 40s]\n",
      "val_accuracy: 0.7041000127792358\n",
      "\n",
      "Best val_accuracy So Far: 0.7271000146865845\n",
      "Total elapsed time: 00h 22m 31s\n"
     ]
    }
   ],
   "source": [
    "tuner.search(x_train, y_train, epochs=10, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best learning rate: 0.0007068016444742155\n",
      "Best optimizer: rmsprop\n"
     ]
    }
   ],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"Best learning rate: {best_hps.get('lr')}\")\n",
    "print(f\"Best optimizer: {best_hps.get('optimizer')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1250/1250 [==============================] - 14s 10ms/step - loss: 1.3223 - accuracy: 0.5411 - val_loss: 1.7489 - val_accuracy: 0.4863\n",
      "Epoch 2/20\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.9406 - accuracy: 0.6744 - val_loss: 1.2272 - val_accuracy: 0.5940\n",
      "Epoch 3/20\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.7617 - accuracy: 0.7365 - val_loss: 1.2008 - val_accuracy: 0.6188\n",
      "Epoch 4/20\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.6227 - accuracy: 0.7874 - val_loss: 1.1433 - val_accuracy: 0.6653\n",
      "Epoch 5/20\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.5104 - accuracy: 0.8249 - val_loss: 1.3943 - val_accuracy: 0.6742\n",
      "Epoch 6/20\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 0.4081 - accuracy: 0.8580 - val_loss: 1.1353 - val_accuracy: 0.6943\n",
      "Epoch 7/20\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.3375 - accuracy: 0.8817 - val_loss: 1.4566 - val_accuracy: 0.6850\n",
      "Epoch 8/20\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.2770 - accuracy: 0.9043 - val_loss: 1.5579 - val_accuracy: 0.6464\n",
      "Epoch 9/20\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 0.2353 - accuracy: 0.9193 - val_loss: 1.4037 - val_accuracy: 0.7065\n",
      "Epoch 10/20\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.1960 - accuracy: 0.9336 - val_loss: 1.4818 - val_accuracy: 0.7049\n",
      "Epoch 11/20\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 0.1734 - accuracy: 0.9400 - val_loss: 1.3693 - val_accuracy: 0.7201\n",
      "Epoch 12/20\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 0.1505 - accuracy: 0.9480 - val_loss: 1.6586 - val_accuracy: 0.7084\n",
      "Epoch 13/20\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 0.1404 - accuracy: 0.9526 - val_loss: 1.7768 - val_accuracy: 0.7015\n",
      "Epoch 14/20\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.1336 - accuracy: 0.9575 - val_loss: 1.8990 - val_accuracy: 0.7066\n",
      "Epoch 15/20\n",
      "1250/1250 [==============================] - 12s 9ms/step - loss: 0.1246 - accuracy: 0.9592 - val_loss: 2.3853 - val_accuracy: 0.6668\n",
      "Epoch 16/20\n",
      "1250/1250 [==============================] - 12s 9ms/step - loss: 0.1171 - accuracy: 0.9625 - val_loss: 2.3988 - val_accuracy: 0.6784\n",
      "Epoch 17/20\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.1121 - accuracy: 0.9641 - val_loss: 2.0763 - val_accuracy: 0.7093\n",
      "Epoch 18/20\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.1002 - accuracy: 0.9678 - val_loss: 1.9918 - val_accuracy: 0.7146\n",
      "Epoch 19/20\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0961 - accuracy: 0.9700 - val_loss: 2.2959 - val_accuracy: 0.7118\n",
      "Epoch 20/20\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0935 - accuracy: 0.9708 - val_loss: 2.1699 - val_accuracy: 0.7029\n"
     ]
    }
   ],
   "source": [
    "final_model = tuner.hypermodel.build(best_hps)\n",
    "history = final_model.fit(x_train, y_train, epochs=20, validation_data=(x_test, y_test), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 5ms/step - loss: 2.1699 - accuracy: 0.7029\n",
      "Final Test Loss: 2.169945478439331\n",
      "Final Test Accuracy: 0.7028999924659729\n"
     ]
    }
   ],
   "source": [
    "final_loss, final_accuracy = final_model.evaluate(x_test, y_test)\n",
    "print(f\"Final Test Loss: {final_loss}\")\n",
    "print(f\"Final Test Accuracy: {final_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
